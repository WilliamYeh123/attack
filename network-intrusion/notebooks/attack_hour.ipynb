{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Filter warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from deepod.models.tabular import DeepSVDD, DeepIsolationForest, ICL, GOAD\n",
    "from deepod.models.time_series import AnomalyTransformer, TimesNet, DeepIsolationForestTS\n",
    "import torch\n",
    "\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "# Import us custom classes\n",
    "%run -i '../src/transfxns.py'\n",
    "%run -i '../src/unsup_ml.py'\n",
    "# Import ss custom class\n",
    "%run -i '../src/ss_transfxns.py'\n",
    "%run -i '../src/ss_ml.py'\n",
    "%run -i '../src/sup_ml.py'\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Instantiate the classes of unspervised learning\n",
    "transfxn = TransformationPipeline()\n",
    "model = UnsupervisedModels()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Instantiate the class of semi-supervised learning\n",
    "# transfxn_ss = TransformationPipelineSS()\n",
    "# model_ss = SemiSupervised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7680227\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'eps_hour.csv'\n",
    "\n",
    "df_total = pd.read_csv(csv_file_path)\n",
    "df_total.columns = ['create_time','count']\n",
    "min_value = 0.2\n",
    "max_value = 0.8\n",
    "max_count = df_total['count'].max()\n",
    "min_count = df_total['count'].min()\n",
    "\n",
    "print(max_count)\n",
    "print(min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df['create_time'] = pd.to_datetime(df['create_time'])\n",
    "    df['hour'] = df['create_time'].dt.hour\n",
    "    # Extract the minute part of the 'create_time' column\n",
    "    df['minute'] = df['create_time'].dt.minute\n",
    "\n",
    "    df['day'] = df['create_time'].dt.dayofweek\n",
    "\n",
    "    # Assuming df is your DataFrame with a 'minute' column\n",
    "    # Convert the 'minute' column to numeric (to handle any non-numeric entries)\n",
    "    # df['minute'] = pd.to_numeric(df['minute'], errors='coerce')\n",
    "\n",
    "    # # Generate a DataFrame with all minutes from 0 to 59\n",
    "    # all_minutes = pd.DataFrame({'minute': range(60)})\n",
    "\n",
    "    # # Merge the existing DataFrame with the generated DataFrame to fill missing minutes\n",
    "    # df = pd.merge(all_minutes, df, on='minute', how='left')\n",
    "\n",
    "    # Fill missing values with 0 for the 'count' column\n",
    "    #df['count'].fillna(0, inplace=True)\n",
    "\n",
    "    #df['count'] = min_value+(max_value-min_value)*(df['count']-min_count)/(max_count-min_count)\n",
    "    first_index = df.index[df['minute'] == 0].min()\n",
    "\n",
    "    data = []\n",
    "    for i in range(int(len(df[first_index:])/60)):\n",
    "        temp = df[60*i:(i+1)*60]['count'].values.tolist()\n",
    "        temp = min_value+(max_value-min_value)*(temp-min_count)/(max_count-min_count)\n",
    "\n",
    "        week = [0]*7\n",
    "        week[df.iloc[24*i]['day']] = 1\n",
    "        temp = np.concatenate((temp, week))\n",
    "\n",
    "        hour = [0]*24\n",
    "        hour[df.iloc[24*i]['hour']] = 1\n",
    "        temp = np.concatenate((temp, hour))\n",
    "        data.append(temp)\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(df_total)\n",
    "pca = PCA(n_components=10)\n",
    "df_pca = pca.fit_transform(df)\n",
    "X_scaled = df_pca\n",
    "#device = torch.device(\"cpu\")\n",
    "#X_train = torch.tensor(df.values, dtype=torch.float32)\n",
    "#print(X_scaled.shape)\n",
    "\n",
    "clf = DeepIsolationForestTS()\n",
    "clf.fit(X_scaled)\n",
    "scores = clf.decision_function(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the threshold based on the 90th percentile\n",
    "threshold = pd.Series(scores).quantile(0.9)\n",
    "#threshold = 1\n",
    "\n",
    "# Create a list to store the labels ('attack' or 'normal')\n",
    "labels = ['attack' if score >= threshold else 'normal' for score in scores]\n",
    "# for i in range(len(labels)):\n",
    "#     if labels[i]=='attack':\n",
    "#         #print(X_scaled[i])\n",
    "#         print(i)\n",
    "\n",
    "# Create a DataFrame for visualization or further analysis\n",
    "result_df = pd.DataFrame({'Anomaly Score': scores, 'Label': labels})\n",
    "\n",
    "print(labels)\n",
    "\n",
    "# PCA plot with raw predicted labels\n",
    "transfxn.pca_plot(scaler.fit_transform(X_scaled), labels, palette = ['r', 'lime','y'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
